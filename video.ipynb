{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikrishnavansi/Gemini-video-analysis/blob/main/video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import cv2\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import logging"
      ],
      "metadata": {
        "id": "pl5sJdUl718W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def analyze_video(video_path):\n",
        "    \"\"\"Analyzes a video using Gemini and annotates it with bounding boxes.\"\"\"\n",
        "\n",
        "    try:\n",
        "        logging.info(f\"Starting video analysis for: {video_path}\")\n",
        "\n",
        "        # Upload the video\n",
        "        video_file = genai.upload_file(path=video_path)\n",
        "\n",
        "        # Wait for video processing to complete\n",
        "        while video_file.state.name == \"PROCESSING\":\n",
        "            logging.info(\"Video is still processing. Waiting...\")\n",
        "            time.sleep(10)\n",
        "            video_file = genai.get_file(video_file.name)\n",
        "        logging.info(\"Video processing complete.\")\n",
        "\n",
        "        # Calculate video length\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        video_length = total_frames / fps\n",
        "        cap.release()\n",
        "        logging.info(f\"Video length: {video_length} seconds\")\n",
        "\n",
        "        # Define the prompt (using f-strings for clarity)\n",
        "        prompt = f\"\"\"Identify and locate all objects and features present in the video throughout its entire duration from 0 seconds to {video_length} seconds.This includes furniture, appliances, décor, structural elements, and any other detectable items.\n",
        "\n",
        "                        For each identified object or feature, provide its bounding box, condition, and appearance time in the video. If an object appears multiple times, include separate entries with the precise timestamps for each instance, along with the duration it is visible.\n",
        "\n",
        "                        Ensure the following:\n",
        "                        1. All items are accounted for, even if they appear intermittently or across multiple frames.\n",
        "                        2. The start time and end time for each item are accurate and correspond to the time window during which the object is visible in the video.\n",
        "                        3. The last `end_time` for any object should match the video’s final time, which is {video_length} seconds.\n",
        "                        4. Timestamps for items should span the complete duration of the video, from the start (0 seconds) to the video’s end (video length).\n",
        "                        5. Ensure that no object or feature is skipped in the annotation. If an object appears in any frame, include it, and ensure its end time reflects its actual disappearance.\n",
        "                        6. Objects appearing multiple times should have separate entries for each instance with accurate start and end times.\n",
        "\n",
        "                        The output should be provided in the following JSON format:\n",
        "\n",
        "                        [\n",
        "                          {{ \"totalvideo_length\":seconds,\n",
        "                            \"item_name\": \"string\",\n",
        "                            \"condition\": \"string\",\n",
        "                            \"bounding_box\": Return a bounding box for each of the objects in this image in [ymin, xmin, ymax, xmax] format.(Provide accurate bounding box),\n",
        "                            \"start_time\": seconds,  // The time in seconds when this object first appears\n",
        "                            \"end_time\": seconds    // The time in seconds when this object disappears\n",
        "                          }},\n",
        "                          {{\n",
        "                            // ... more items (including multiple entries for objects appearing multiple times)\n",
        "                          }}\n",
        "                        ]\n",
        "\n",
        "                        Make sure that the list of items includes those visible throughout the video, and that timestamps reflect the full duration of the video (from 0s to {video_length}s).\"\"\" # Your prompt here\n",
        "\n",
        "        model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "        # Generate content with JSON response\n",
        "        response = model.generate_content(\n",
        "            [video_file, prompt],\n",
        "            generation_config=genai.GenerationConfig(response_mime_type=\"application/json\"),\n",
        "            request_options={\"timeout\": 600},\n",
        "        )\n",
        "\n",
        "        # Extract JSON data (with improved error handling)\n",
        "        try:\n",
        "            data = json.loads(response.text)\n",
        "        except json.JSONDecodeError:\n",
        "            logging.error(f\"JSONDecodeError: {response.text}\") #Log full response\n",
        "            match = re.search(r'\\[(?:[^[\\]]|(?R))*\\]', response.text)\n",
        "            if match:\n",
        "                try:\n",
        "                    data = json.loads(match.group(0))\n",
        "                except json.JSONDecodeError:\n",
        "                    logging.error(\"Could not extract valid JSON even with regex.\")\n",
        "                    return None\n",
        "            else:\n",
        "                logging.error(\"Could not find JSON in the response.\")\n",
        "                return None\n",
        "        logging.info(\"JSON data loaded successfully.\")\n",
        "\n",
        "        # Annotate the video\n",
        "        output_video_path = \"video.mp4\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "        def generate_random_color():\n",
        "            return [int(np.random.randint(0, 255)) for _ in range(3)]\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "            for item in data:\n",
        "                if 'bounding_box' not in item or not isinstance(item['bounding_box'], list) or len(item['bounding_box']) != 4:\n",
        "                    logging.warning(f\"Invalid bounding box format for item: {item}\")\n",
        "                    continue\n",
        "                ymin, xmin, ymax, xmax = map(int, item['bounding_box']) #convert to int\n",
        "                if any(val<0 for val in [ymin,xmin,ymax,xmax]) or xmax<xmin or ymax<ymin:\n",
        "                    logging.warning(f\"Invalid bounding box values for item: {item}\")\n",
        "                    continue\n",
        "                if 'start_time' not in item or 'end_time' not in item:\n",
        "                    logging.warning(f\"Missing start or end time for item: {item}\")\n",
        "                    continue\n",
        "                start_time = item['start_time']\n",
        "                end_time = item['end_time']\n",
        "                if start_time <= current_time <= end_time:\n",
        "                    color = generate_random_color()\n",
        "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "                    label = f\"{item.get('item_name', 'Unknown')} ({item.get('condition', 'Unknown')})\"\n",
        "                    label_position = (xmin, ymin - 10 if ymin - 10 > 10 else ymin + 10)\n",
        "                    cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        logging.info(f\"Annotated video saved to {output_video_path}\")\n",
        "        return output_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HkqTQt8lRBZp",
        "outputId": "3e548e7a-77b8-4269-dace-7d9d21d7ec83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis complete. Annotated video saved to: video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_file_path = \"/content/WhatsApp Video 2024-12-23 at 23.47.01.mp4\"  # Replace with your video path\n",
        "output_video = analyze_video(video_file_path)\n",
        "if output_video:\n",
        "    print(f\"Analysis complete. Annotated video saved to: {output_video}\")\n",
        "else:\n",
        "    print(\"Video analysis failed.\")"
      ],
      "metadata": {
        "id": "9e_ee1GA0s82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}